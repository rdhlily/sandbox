{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Attempting to change multiple file names in folder "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"/Users/lilyfalk/Downloads\")\n",
    "os.getcwd()\n",
    "#OS module - fxns for interacting with operating system"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.rename(src, dst) where src is source and dst is destication with new name\n",
    "#os.listdir('Src') lists contents in source folder\n",
    "#Adapted from code available: [https://www.geeksforgeeks.org/rename-multiple-files-using-python/] and [https://stackoverflow.com/questions/2759067/rename-multiple-files-in-a-directory-in-python]\n",
    "\n",
    "#function to rename multiple files\n",
    "def main():\n",
    "    for count, filename in enumerate(os.listdir(\"pgp_data\")):  #enumerate is function that alows index through a loop\n",
    "        dst = filename[-6:-4]+\"_\"+filename[0:3]+\"_\"+filename[-9:-7]+\".zip\"\n",
    "        src = 'pgp_data/' + filename\n",
    "        dst = 'pgp_data/' + dst\n",
    "\n",
    "        #rename function will rename all the files\n",
    "        os.rename(src, dst)\n",
    "\n",
    "#Driver code - (a program that uses the class or algorithm you're developing - used for testing code while developing it)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #calling main() fxn\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, filename in enumerate(os.listdir(\"pgp_data\")):  #enumerate is function that alows index through a loop\n",
    "    dst = filename[-6:-4]+\"_\"+filename[0:3]+\"_\"+filename[-9:-7]+\".zip\"\n",
    "    src = 'pgp_data/' + filename\n",
    "    dst = 'pgp_data/' + dst\n",
    "\n",
    "        #rename function will rename all the files\n",
    "    os.rename(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(os.listdir(\"pgp_data\"))):\n",
    " #   i = 1 +i\n",
    "for filename in os.listdir(\"pgp_data\"):\n",
    "    newfilename = filename[-6:-4]+\"_\"+filename[0:3]+\"_\"+filename[-9:-7]+\".zip\"\n",
    "    os.rename(filename, newfilename) #src_dir_fd = \"pgp_data/\", dst_dir_fd = \"pgp_data_renamed/\")\n",
    "    print(newfilename)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"pgp_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"pgp_data\"):\n",
    "    print(\"year =\", filename[-9:-7], \"state =\", filename[-6:-4])\n",
    "newfilename = filename[-6:-4]+\"_pgp_\"+filename[-9:-7]\n",
    "newfilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "source": [
    "## Script from Adriana to modify Readme and change from .md to .txt\n",
    "https://github.com/nonpartisan-redistricting-datahub/rdh-resources/blob/main/mggg_data_downloads.ipynb "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work in directory with all data downloads\n",
    "\n",
    "os.chdir('pgp_data_renamed/')\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Get all of the zipped directories downloaded from MGGG github\" - In my case, downloaded from OpenPrecincts\n",
    "\n",
    "files = [file for file in os.listdir() if '_pgp_18.zip' in file] #can do _16 sep. Include the .zip so it stops on unzipped folders\n",
    "files"
   ]
  },
  {
   "source": [
    "### Function to unzip file and give new file name"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip(zip_file_name, unzipped_file_name):\n",
    "    with ZipFile(zip_file_name, 'r') as zipObj:\n",
    "        zipObj.extractall(unzipped_file_name) #extract all needs to accept a string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('ok_pgp_18/README.md'):\n",
    "    html = markdown.markdown(open('ok_pgp_18/README.md').read()) #some PGP readme is .txt, some is .md, some have their verification\n",
    "    parser = BeautifulSoup(html) #making a parser to read md file, making a list \n",
    "    #beautiful soup is removing the md formatting... normally parser used to show all headings, etc, see formatting\n",
    "    text = \"\".join(parser.findAll(text=True)) #taking a list of strings and connects them\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate over every MGGG zip file, unzip the file, and then get all of the fields for the metadata template. Save them as a .txt. For the description field, read in a csv file that has the descriptions saved for each state.\n",
    "#modified to make unzip work, and then stopped bc was less applicable to PGP\n",
    "\n",
    "for file in files: \n",
    "    file_dir = file.replace('.zip','')\n",
    "    unzip(file, file_dir)\n",
    "    md_file = file_dir + \"/README.md\"\n",
    "    txt_file = file_dir + \"/README.txt\" #TODO: add another if statement\n",
    "    \n",
    "    if os.path.exists(md_file):\n",
    "        html = markdown.markdown(open(md_file).read()) #some PGP readme is .txt, some is .md, some have their verification\n",
    "        text = \"\".join(BeautifulSoup(html).findAll(text=True))\n",
    "\n",
    "    # meta-data fields - this depends on the MGGG MD file format being constant. \n",
    "        description = '' #TO DO: feed in from notion notes Description field saved as a csv\n",
    "        date_retrieval = '07/12/2020' #TODO: use python fxn to read date retrieval from computer\n",
    "        sources = text[text.find('Sources'):text.find('Metadata')].replace('Sources\\n','')\n",
    "        fields_metadata = ''\n",
    "        fields = text[text.find('Metadata'):text.find('Preprocessing')].replace('Metadata\\n','')\n",
    "        processing_steps = text[text.find('Preprocessing'):text.find('Metadata')].replace('Processing\\n','')\n",
    "    ##additional_notes = text[text.find('Rating'):].replace('Rating\\n','Rating from MGGG: ')\n",
    "\n",
    "        with open('./' + file_dir + '/README.txt','w+') as f:\n",
    "            f.write(description)\n",
    "            f.write('\\n## RDH Date retrieval\\n' + date_retrieval)\n",
    "            f.write('\\n\\n## Sources\\n' + sources)\n",
    "            f.write('\\n## Fields metadata' + fields_metadata)\n",
    "            f.write('\\n## Fields' + fields)\n",
    "            f.write('## Processing Steps\\n' + processing_steps)\n",
    "        ##f.write('\\n## Additional Notes\\n' + additional_notes)"
   ]
  },
  {
   "source": [
    "## Notes from convo with baxter \n",
    "#### Hashing fxn\n",
    "use check sum - using a \n",
    "takes a file\n",
    "hashes file\n",
    "compares the hash (aka digest) and making sure they're the same\n",
    "Hashing fxn baxter has used in past is \"md5\" message digest 5\n",
    "take some arbitrary file, then return a fixed length sequence of bytes\n",
    "want to be consistent in the way you compare the bytes\n",
    "take the hexadecimal interpretation of the digest as a string, \n",
    "then do a string comparison"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## The next few blocks are used for looking at the congressional boundary data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR BOUNDARY DATA - CONGRESSIONAL: Need to filter by county fips\n",
    "#create new .csv for each state\n",
    "#LA FP = 22\n",
    "#MI FP = 26\n",
    "#MO FP = 29\n",
    "#MS FP = 28\n",
    "#use a mask to look at is\n",
    "#Then, include info just for that state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_2018_us = gpd.read_file('./prev_leg_boundaries/cb_2018_us_cd116_500k/cb_2018_us_cd116_500k.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_2018_us.head(2)"
   ]
  },
  {
   "source": [
    "## The next two blocks are code to change the file name based on directory name (post unzip of named zip file)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_file_name(dir_name):\n",
    "    os.chdir(dir_name)\n",
    "    for full_file_name in [x for x in os.listdir() if not x[0] == '.']:\n",
    "        old_name,file_type = full_file_name.split('.',1)\n",
    "        new_file_name = '.'.join([dir_name, file_type])\n",
    "        print(\"Renaming {} to {}\".format(full_file_name, new_file_name)) \n",
    "        os.rename(full_file_name, new_file_name)\n",
    "    os.chdir('..')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/lilyfalk/Downloads/pgp_data_renamed/unzipped/')\n",
    "for dir_name in [x for x in os.listdir() if not x[0] == '.']:\n",
    "    change_file_name(dir_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing readme name in given directory\n",
    "def change_readme_name(dir_name):\n",
    "    os.chdir(dir_name)\n",
    "    for full_file_name in [x for x in os.listdir() if x[-3:] == 'txt']:\n",
    "        file_name,file_type = full_file_name.split('.',1)\n",
    "        new_readme_name = '.'.join([\"README\", file_type])\n",
    "        print(\"Renaming {} to {}\".format(full_file_name, new_readme_name)) \n",
    "        os.rename(full_file_name, new_readme_name)\n",
    "    os.chdir('..')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing readme name in many directories:\n",
    "dir_name = os.chdir('/Users/lilyfalk/Downloads/pgp_data_renamed/unzipped/')\n",
    "for dir_name in [x for x in os.listdir() if not x[0] == '.']:\n",
    "    change_readme_name(dir_name)"
   ]
  },
  {
   "source": [
    "## The next block of code is a script to change the contents of PGP readme's for RDH purposes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write script to create readme for each state, then I place in each folder, or program to place in each folder, then in folder, rename to say just \"readme\"\n",
    "\n",
    "os.chdir('/Users/lilyfalk/Downloads/pgp_data_renamed/unzipped')\n",
    "date_retrieval = \"07/12/2020\"\n",
    "for file in files:\n",
    "    if file != '.DS_Store':\n",
    "        os.chdir(file)\n",
    "\n",
    "        state = file[0:2]\n",
    "        source = \"https://openprecincts.org/\" + state\n",
    "        year = \"20\" + file[7:9]\n",
    "        readme = open('README.txt', 'w')\n",
    "        readme.write(\"Description: \"+ year +' '+ ' ' + state.upper() + \" precinct and election shapefile\")\n",
    "        readme.write('\\n\\n## RDH Date retrieval\\n' + date_retrieval)\n",
    "        readme.write('\\n\\n## Sources\\n' + \"The RDH retrieved this data from\" + source)\n",
    "        readme.write('\\n\\n## Fields metadata')\n",
    "        readme.write('\\n\\n## Fields')\n",
    "        readme.write('\\n\\n## Processing Steps\\n')\n",
    "        readme.close()\n",
    "\n",
    "        os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Block Projections:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Once I have all data, print file size and file name into csv and copy into google sheet\n",
    "'\\n also use state fip to state name code to print state name for each\\n'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "For block projections, put readme in each folder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_readme_in_file(path, file_id):\n",
    "    os.chdir(path)\n",
    "    files = [file for file in os.listdir() if file_id in file]\n",
    "    for file in files:\n",
    "        source = ('./README.txt')   #Begin in bg/block folder\n",
    "        destination = file\n",
    "        dest = shutil.copy(source, destination)\n",
    "        print('README copied to: ', file)"
   ]
  },
  {
   "source": [
    "Change directory name"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from op_verification.reference_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dir_name(path, file_id):\n",
    "    os.chdir(path)\n",
    "    files = [file for file in os.listdir() if file_id in file]\n",
    "    for file in files:\n",
    "        (label, fips) = file.split('=')\n",
    "        if fips == '72':\n",
    "            full_state = 'Puerto Rico'\n",
    "            state = 'PR' \n",
    "        else:\n",
    "            full_state = fips_to_state[int(fips)]\n",
    "            state = state_to_state_po[full_state].lower()\n",
    "        if 'bg' in path:\n",
    "            new_name = state + '_2021_2030_bg_proj'\n",
    "        elif 'block' in path:\n",
    "            new_name = state + '_2021_2030_b_proj'\n",
    "        os.rename(file, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "Rename file from parent directory name using path above"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_file_from_dir(parent_path):\n",
    "    os.chdir(parent_path)\n",
    "    directory_list = [x for x in os.listdir() if not x[0] == '.' and os.path.isdir(x)] #this is a list of all nonhidden files \n",
    "    cur_dir = os.getcwd()\n",
    "    for dir_name in directory_list:\n",
    "        sub_files = [x for x in os.listdir(dir_name) if x.endswith('.csv')]\n",
    "        old_name  = cur_dir + \"/\" +  dir_name + \"/\" +  sub_files[0]\n",
    "        new_name = cur_dir + \"/\" +  dir_name + \"/\" + os.path.basename(dir_name) + \".csv\"\n",
    "        print( f\"{old_name} -> {new_name}\")\n",
    "        os.rename(old_name, new_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "source": [
    "Creating Zip Files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the internet:\n",
    "def get_all_file_paths(directory): \n",
    "  \n",
    "    # initializing empty file paths list \n",
    "    file_paths = [] \n",
    "  \n",
    "    # crawling through directory and subdirectories \n",
    "    for root, directories, files in os.walk(directory): \n",
    "        for filename in files: \n",
    "            # join the two strings in order to form the full filepath. \n",
    "            filepath = os.path.join(root, filename) \n",
    "            file_paths.append(filepath) \n",
    "  \n",
    "    # returning all file paths \n",
    "    return file_paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_in_directory(path):\n",
    "    os.chdir(path)\n",
    "    directory_list = [x for x in os.listdir() if not x[0] == '.' and os.path.isdir(x)]\n",
    "    for dir_name in directory_list:\n",
    "        directory = './'+dir_name\n",
    "        file_paths = get_all_file_paths(directory)\n",
    "        zip_name = dir_name + '.zip'\n",
    "        with ZipFile(zip_name, 'w') as zip:\n",
    "            for file in file_paths:\n",
    "                zip.write(file)\n",
    "        print('All files zipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = ('/Users/lilyfalk/Downloads/projections/b_p1_by_state/')\n",
    "os.chdir(parent_path)\n",
    "for folder in os.listdir():\n",
    "    if not folder[0] == '.':\n",
    "        path = (parent_path + folder)\n",
    "        print(path)\n",
    "        zip_in_directory(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n"
     ]
    }
   ],
   "source": [
    "zip_in_directory('/Users/lilyfalk/Downloads/projections/b_p2_by_state/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n",
      "All files zipped\n"
     ]
    }
   ],
   "source": [
    "zip_in_directory('/Users/lilyfalk/Downloads/projections/b_p1_by_state/')"
   ]
  },
  {
   "source": [
    "Removing non-zip files from folder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_nonzip_dir(path):\n",
    "    os.chdir(path)\n",
    "    directory_list = [x for x in os.listdir() if not x[0] == '.' and os.path.isdir(x)] #this is a list of all nonhidden files \n",
    "    cur_dir = os.getcwd()\n",
    "    for dir_name in directory_list: \n",
    "        if [x for x in os.listdir(dir_name) if x[-4:] != '.zip']:\n",
    "            shutil.rmtree(dir_name)#shutil.rmtree is needed to remove a directory with contents, whereas os.rmdir for empty dirs\n",
    "\n"
   ]
  },
  {
   "source": [
    "Functions to rename file and directory to account for p1 and p2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_csv(path):\n",
    "    os.chdir(path)\n",
    "    proj_dir = [state_csv for state_csv in os.listdir() if state_csv.endswith('.csv')\n",
    "    for state_csv in proj_dir:\n",
    "        [file_name, file_type] = state_proj.split('.', 1)\n",
    "        new_file_name = file_name + '_p1' + file_type\n",
    "        os.rename(state_csv, new_file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_dir(path):\n",
    "    os.chdir(path)\n",
    "    state_projs = [state_proj for state_proj in os.listdir() if not state_proj[0] == '.' and os.path.isdir(state_proj)]\n",
    "    for state_proj in state_projs:\n",
    "        src = state_proj\n",
    "        dest = state_proj + '_p2'\n",
    "        os.rename(src, dest)"
   ]
  },
  {
   "source": [
    "Below code not working... Not sure why. Ended up removing zip files manually"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_zip_dir(path):\n",
    "    os.chdir(path)\n",
    "    directory_list = [x for x in os.listdir() if not x[0] == '.' and os.path.isdir(x)] #this is a list of all nonhidden files \n",
    "    cur_dir = os.getcwd()\n",
    "    for dir_name in directory_list: \n",
    "        if [x for x in os.listdir(dir_name) if x[-4:] == '.zip']:\n",
    "            shutil.rmtree(dir_name)#shutil.rmtree is needed to remove a directory with contents, whereas os.rmdir for empty dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/lilyfalk/Downloads/block_boundaries_copy/')\n",
    "directory_list = [x for x in os.listdir() if not x[0] == '.' and os.path.isdir(x)]\n",
    "for x in directory_list:\n",
    "    zip_rm = [y for y in os.listdir(x) if not y[0] == '.' and os.path.isdir(y)]\n",
    "    for y in zip_rm:\n",
    "        rm_zip_dir('./'+y)\n",
    "        os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DONE: Today, I need to implement function to copy readme into each folder\n",
    "#  DONE:need to rename folder for each state\n",
    "# DONE: Then need to rename each file in each folder with az_2021_2030_bg_proj or az_2021_2030_block_proj using state fips\n",
    "    #DONE: could make it auto know bg vs blcok but for simplicity sake likely will not\n",
    "# Then zip every folder \n",
    "# Remove unzipped files from folders\n",
    "# need to add p1 or p2 to each directory name and each file name\n",
    "# TODO: upload to s3\n",
    "# Retrieve file info - print file size and state into csv\n",
    "# populate bulk upload sheet with file size, state, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve and export to csv \n",
    "import csv\n",
    "# file size\n",
    "# state - get state abreviation from name, then process to be state name\n",
    "# ^key information, then can get specific on column infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['Title', 'Updated', 'Source', 'Description', 'State', 'File_size', 'Years', 'Dataset Types', 'Format', 'Size','URL']\n",
    "rows = [ ] #TODO: create dictionary\n",
    "filename = 'bulk_projection.csv'\n",
    "\n",
    "\n",
    "with open(filename, 'w') as csvfile:    #write to csv file \n",
    "    csvwriter = csv.writer(csvfile, dialect = 'excel')      #create the csv writer object #TODO: maybe use csv.DictWriter() instead\n",
    "    csvwriter.writerow(fields)   # write the data fields\n",
    "    csvwriter.writerows(rows)    # write the data rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(path):\n",
    "    os.chdir(path)\n",
    "    cur_dir = os.getcwd()\n",
    "    file_sizes = {}     #creating + opening dictionary\n",
    "    keys = range(52)\n",
    "    projs = [zip_proj for zip_proj in os.listdir() if not zip_proj[0] == '.']\n",
    "    for i in keys:\n",
    "        for zip_proj in projs:\n",
    "            proj_path = cur_dir + '/' + zip_proj \n",
    "            #file_name = os.path.basename(proj_path)\n",
    "            size_zip_proj = os.path.getsize(proj_path)\n",
    "            size_mb = size_zip_proj/(1000**2)    # getsize returns in bytes, convert to mb - use 1000 or 1024?\n",
    "            file_sizes[i] = size_mb\n",
    "    print(file_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#base - Attempt 1 at dictionary creation\n",
    "ile_to_state = {}\n",
    "\n",
    "\n",
    "#creating dictionary with sizes\n",
    "file_to_size = {}  #initializing outside of the loop\n",
    "for zip_proj in os.listdir():\n",
    "    if not zip_proj[0] == '.':\n",
    "        #file size\n",
    "        size_zip_proj = os.path.getsize(zip_proj)\n",
    "        size_mb = size_zip_proj/(1000**2) \n",
    "        file_to_size[zip_proj] = size_mb\n",
    "        #state name\n",
    "        state_abrv = zip_proj[0:2]\n",
    "        state = state_abbreviation_to_state_name.get(state_abrv.upper(), 'Puerto Rico') #because one missing can set default\n",
    "        file_to_state[zip_proj] = state\n",
    "file_to_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt two - create dictionaries that are converted to DFs and then converted to csvs\n",
    "#creating dictionaries for csv\n",
    "path = '/Users/lilyfalk/Downloads/block_boundaries_copy/bg_p1_by_state/'\n",
    "os.chdir(path)\n",
    "name_to_col = {'Title': [], 'Updated1': [], 'Source': ['HaystaqDNA']*53, 'Description':[],'state': [], 'Years Tags': [], 'Dataset Types': [], 'Title in Listing': [], 'readme name': [], 'show criteria': [], 'format': [], 'size':[], 'Updated2':[], 'URL': []} #TODO: add other columns to dictionary, add logic in loop\n",
    "for zip_proj in os.listdir():\n",
    "    if not zip_proj[0] == '.':\n",
    "        #Updated\n",
    "        update_date = '12/15/2020'\n",
    "        name_to_col['Updated1'].append(update_date)\n",
    "        #Source\n",
    "        ##source = 'HaystaqDNA'\n",
    "        ##name_to_col['Source'].append(source)\n",
    "        #Dataset Types\n",
    "        data_type = 'projections'\n",
    "        name_to_col['Dataset Types'].append(data_type)\n",
    "        #state name\n",
    "        state_abrv = zip_proj[0:2]\n",
    "        state_name = state_abbreviation_to_state_name.get(state_abrv.upper(), 'Puerto Rico')\n",
    "        name_to_col['state'].append(state_name)#because one missing can set default\n",
    "        #Title\n",
    "        #ex: Haystaq 2021 to 2030 Alaska block level projection\n",
    "        title = \"Haystaq 2021 to 2030 \" + state_name + \" Block Group Level Projection P1\"\n",
    "        name_to_col['Title'].append(title)\n",
    "        #Title in Listing\n",
    "        title_list = '2021 to 2030 Block Group Population Projection P1'\n",
    "        name_to_col['Title in Listing'].append(title_list)\n",
    "        #Description\n",
    "        description = '2021 to 2030 ' + state_name + ' Block Group Level Projection P1'\n",
    "        name_to_col['Description'].append(description)\n",
    "        #Years Tags\n",
    "        data_year = zip_proj[3:7] + ' ' + zip_proj[8:12]\n",
    "        name_to_col['Years Tags'].append(data_year)\n",
    "        #readme name\n",
    "        readme = 'readme_'+ zip_proj[:-4] + '.txt'\n",
    "        name_to_col['readme name'].append(readme)\n",
    "        #show criteria\n",
    "        show = 'no'\n",
    "        name_to_col['show criteria'].append(show)\n",
    "        #format\n",
    "        file_type = 'csv'\n",
    "        name_to_col['format'].append(file_type)\n",
    "        #file size\n",
    "        size_zip_proj = os.path.getsize(zip_proj)\n",
    "        size_mb = size_zip_proj/(1000**2) \n",
    "        name_to_col['size'].append(size_mb)\n",
    "        #Updated2\n",
    "        name_to_col['Updated2'].append(update_date)\n",
    "        #URL\n",
    "        folder_cat = 'projections/'\n",
    "        sub_dir = 'bg_p1_by_state/'\n",
    "        url = 'https://rdh-web-storage.s3.us-east-2.amazonaws.com/web_ready_stage/' + folder_cat + sub_dir + zip_proj\n",
    "        name_to_col['URL'].append(url)\n"
   ]
  },
  {
   "source": [
    "## Change block file names"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip(path, src_path, dest_path, zip_file_name, unzipped_file_name):\n",
    "    os.chdir(path)\n",
    "    with ZipFile(zip_file_name, 'r') as zipObj:\n",
    "        zipObj.extractall(unzipped_file_name) \n",
    "        \n",
    "    shutil.move(src_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip and move\n",
    "path = '/Users/lilyfalk/Downloads/projections/bg_p2_by_state'\n",
    "os.chdir(path)\n",
    "for zip_proj in os.listdir():\n",
    "    if not zip_proj[0] == '.':\n",
    "        zip_file_name = zip_proj\n",
    "        unzipped_file_name = zip_proj[:-4]\n",
    "        src_path = ('/Users/lilyfalk/Downloads/projections/bg_p2_by_state/'+zip_file_name[:-4])\n",
    "        dest_path = ('/Users/lilyfalk/Downloads/projections_unzipped/bg_p2_by_state')\n",
    "\n",
    "        unzip(path, src_path, dest_path, zip_file_name, unzipped_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir('/Users/lilyfalk/Downloads/projections_unzipped/b_p1_by_state/')\n",
    "parent_path = '/Users/lilyfalk/Downloads/projections_unzipped/b_p1_by_state/'\n",
    "for folder in os.listdir():\n",
    "    if not folder[0] == '.':\n",
    "        os.chdir(parent_path + folder)\n",
    "        for subfolder in os.listdir():\n",
    "            if not subfolder[0] == '.':\n",
    "                os.chdir(parent_path + folder + '/' + subfolder)\n",
    "                for file in os.listdir():\n",
    "                    if not file[0] == '.' and file.endswith('.csv'):\n",
    "                        new_name = file[0:12] + '_b_proj_p1.csv'\n",
    "                        os.rename(file, new_name)\n",
    "                        print(file, ' renamed: ', new_name)\n",
    "                #folder.replace('block', 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = '/Users/lilyfalk/Downloads/projections_unzipped/b_p2_by_state_embedded/'\n",
    "os.chdir(parent_path)\n",
    "for folder in os.listdir():\n",
    "    if not folder[0] == '.':\n",
    "        os.chdir(parent_path + folder)\n",
    "        for subfolder in os.listdir():\n",
    "            if not subfolder[0] == '.':\n",
    "                src = parent_path + folder + '/' + subfolder\n",
    "                dest = '/Users/lilyfalk/Downloads/projections_unzipped/b_p2_by_state/'\n",
    "                shutil.move(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = '/Users/lilyfalk/Downloads/projections_unzipped/b_p2_by_state/'\n",
    "for folder in os.listdir():\n",
    "    if not folder[0] == '.':\n",
    "        parent_path = parent_path + folder\n",
    "        for subfolder in os.listdir():\n",
    "            if not subfolder[0] == '.':\n",
    "                parent_path = parent_path + '/' + subfolder\n",
    "                rename_file_from_dir(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}